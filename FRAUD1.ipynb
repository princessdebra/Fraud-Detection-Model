{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67815a74-aed8-47f0-ab55-2b1a212548f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import KMeans\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6194468e-bb3c-4510-92fe-a2b70db02f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: [Errno 2] No such file or directory: 'Final_data (1).csv'\n",
      "Please ensure the file paths are correct and the files are accessible.\n",
      "Training Data Head:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_training' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPlease ensure the file paths are correct and the files are accessible.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining Data Head:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf_training\u001b[49m.head())\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFraud Claims 1 Head:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(df_fraud_claims1.head())\n",
      "\u001b[31mNameError\u001b[39m: name 'df_training' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cell 1: Load Data\n",
    "\n",
    "\n",
    "try:\n",
    "    df_training = pd.read_csv('Final_data (1).csv', encoding='utf-8', low_memory=False)\n",
    "    df_fraud_claims1 = pd.read_csv('MMC Fraud Cases 2_7_2025.csv', encoding='utf-8', low_memory=False)\n",
    "    df_fraud_claims2 = pd.read_csv('RISK REGISTER- 2n July 2025 Updated.csv', encoding='utf-8', low_memory=False)\n",
    "except UnicodeDecodeError:\n",
    "    print(\"UTF-8 decoding failed. Trying 'latin-1' encoding...\")\n",
    "    df_training = pd.read_csv('Final_data (1).csv', encoding='latin-1', low_memory=False)\n",
    "    df_fraud_claims1 = pd.read_csv('MMC Fraud Cases 2_7_2025.csv', encoding='latin-1', low_memory=False)\n",
    "    df_fraud_claims2 = pd.read_csv('RISK REGISTER- 2n July 2025 Updated.csv', encoding='latin-1', low_memory=False)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"Please ensure the file paths are correct and the files are accessible.\")\n",
    "\n",
    "\n",
    "print(\"Training Data Head:\")\n",
    "print(df_training.head())\n",
    "print(\"\\nFraud Claims 1 Head:\")\n",
    "print(df_fraud_claims1.head())\n",
    "print(\"\\nFraud Claims 2 Head:\")\n",
    "print(df_fraud_claims2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd0e961-ad69-4c31-8939-0625497fc96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with low cardinality (few unique values)\n",
    "categorical_cols = [\n",
    "    'relationship',\n",
    "    'gender(claimant)',\n",
    "    'company',\n",
    "    'broad_benefit',\n",
    "    'benefit',\n",
    "    'main_member_gender'\n",
    "]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in df_training.columns:\n",
    "        df_training[col] = df_training[col].astype('category')\n",
    "\n",
    "# Optional: Check 'provider' and 'ailments' as well\n",
    "# Check number of unique values first to ensure it's not too high\n",
    "if 'provider' in df_training.columns and df_training['provider'].nunique() < 5000:\n",
    "    df_training['provider'] = df_training['provider'].astype('category')\n",
    "\n",
    "if 'ailments' in df_training.columns and df_training['ailments'].nunique() < 10000:\n",
    "    df_training['ailments'] = df_training['ailments'].astype('category')\n",
    "\n",
    "# You can check the memory usage before and after to see the improvement\n",
    "print(\"Data types after optimization:\")\n",
    "print(df_training.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b018f240-58ba-46bb-990c-7a5c35c2d5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Initial Data Cleaning and Preprocessing (Training Data)\n",
    "\n",
    "\n",
    "df_training.columns = df_training.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "df_fraud_claims1.columns = df_fraud_claims1.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "df_fraud_claims2.columns = df_fraud_claims2.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Standardize column names where possible across datasets for potential merging or lookups\n",
    "df_fraud_claims1 = df_fraud_claims1.rename(columns={'claim_amount': 'total_payable', 'hospital': 'payee'})\n",
    "\n",
    "# Convert 'ailment_date' and 'dob' to datetime objects in df_training\n",
    "# Specify the format '%d/%m/%Y' to correctly parse Day/Month/Year dates\n",
    "df_training['ailment_date'] = pd.to_datetime(df_training['ailment_date'], format='%d/%m/%Y', errors='coerce')\n",
    "#df_training['dob'] = pd.to_datetime(df_training['dob'], format='%d/%m/%Y', errors='coerce')\n",
    "df_training['date_of_birth(claimant)'] =  pd.to_datetime(df_training['date_of_birth(claimant)'], format='%d/%m/%Y', errors='coerce')\n",
    "# This is the crucial part that creates the 'age' column.\n",
    "current_year = pd.Timestamp.now().year\n",
    "df_training['age'] = current_year - df_training['date_of_birth(claimant)'].dt.year # Ensure this line is run!\n",
    "\n",
    "\n",
    "# Clean 'totals' and 'limit_amount' columns in df_training\n",
    "df_training['totals'] = pd.to_numeric(df_training['total_payable'], errors='coerce')\n",
    "df_training['limit_amount'] = pd.to_numeric(df_training['cover_limit'], errors='coerce')\n",
    "\n",
    "# Display info to check data types after conversion\n",
    "print(\"\\nTraining Data Info after date conversion:\")\n",
    "print(df_training.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584c7196-9b67-4ade-b588-f6f7612ebbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Feature Engineering: Days Since Last Visit\n",
    "# Comments: Calculate the number of days since the last visit for each claimant.\n",
    "# This feature helps identify unusual claim frequency.\n",
    "\n",
    "df_training = df_training.sort_values(by=['claimant_suddo', 'ailment_date'])\n",
    "df_training['days_since_last_visit'] = df_training.groupby('claimant_suddo')['ailment_date'].diff().dt.days.fillna(0)\n",
    "\n",
    "print(\"\\nDays Since Last Visit Feature:\")\n",
    "print(df_training[['claimant_suddo', 'ailment_date', 'days_since_last_visit']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2983d5-d42a-46fa-9da5-bb583125e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Feature Engineering: Grouping Features for Broad Benefit Categories (6 Categories)\n",
    "# Comments: Create binary flags for six specific broad benefit categories: IN-PATIENT, OUT-PATIENT, OPTICAL, DENTAL, MATERNITY, LAST EXPENSE.\n",
    "# This categorizes claims for specific analysis based on these distinct types.\n",
    "\n",
    "# Standardize the 'broad_benefit' column to lower case for consistent matching\n",
    "df_training['broad_benefits_cleaned'] = df_training['broad_benefit'].astype(str).str.lower().str.strip()\n",
    "\n",
    "# Create individual flags for each of the 6 broad benefit categories\n",
    "# Using .str.contains() for flexibility, as one broad benefit entry might cover multiple types (e.g., \"Inpatient Dental\")\n",
    "df_training['is_inpatient_benefit'] = (df_training['broad_benefits_cleaned'].str.contains('in-patient|inpatients', na=False)).astype(int)\n",
    "df_training['is_outpatient_benefit'] = (df_training['broad_benefits_cleaned'].str.contains('out-patient|outpatients', na=False)).astype(int)\n",
    "df_training['is_optical_benefit'] = (df_training['broad_benefits_cleaned'].str.contains('optical', na=False)).astype(int)\n",
    "df_training['is_dental_benefit'] = (df_training['broad_benefits_cleaned'].str.contains('dental', na=False)).astype(int)\n",
    "df_training['is_maternity_benefit'] = (df_training['broad_benefits_cleaned'].str.contains('maternity', na=False)).astype(int)\n",
    "df_training['is_last_expense_benefit'] = (df_training['broad_benefits_cleaned'].str.contains('last expense', na=False)).astype(int)\n",
    "\n",
    "# Note: A single 'broad_benefit' value might contain multiple keywords (e.g., 'inpatient optical').\n",
    "# The .str.contains() method will flag if *any* of the keywords are present.\n",
    "# If strict, mutually exclusive categories are needed (e.g., a claim can only be *either* inpatient *or* optical, but not both),\n",
    "# then this logic would need to be re-evaluated to enforce exclusivity.\n",
    "\n",
    "print(\"\\nBroad Benefit Category Flags:\")\n",
    "print(df_training[['broad_benefit', 'is_inpatient_benefit', 'is_outpatient_benefit',\n",
    "                   'is_optical_benefit', 'is_dental_benefit', 'is_maternity_benefit',\n",
    "                   'is_last_expense_benefit']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f552704-03f2-4ea3-9b8d-b93ac90a0386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Feature Engineering: Calculate Means, Deviations, and Variances for Claims\n",
    "# Comments: Calculate mean, standard deviation, and variance of 'totals' (claim amounts) per claimant.\n",
    "# These statistical measures help identify claims significantly different from a claimant's average.\n",
    "\n",
    "df_training['claim_amount_mean_by_claimant'] = df_training.groupby('claimant_suddo')['totals'].transform('mean')\n",
    "df_training['claim_amount_dev_by_claimant'] = df_training.groupby('claimant_suddo')['totals'].transform('std').fillna(0)\n",
    "df_training['claim_amount_var_by_claimant'] = df_training.groupby('claimant_suddo')['totals'].transform('var').fillna(0)\n",
    "\n",
    "print(\"\\nClaim Amount Statistics by Claimant:\")\n",
    "print(df_training[['claimant_suddo', 'totals', 'claim_amount_mean_by_claimant', 'claim_amount_dev_by_claimant', 'claim_amount_var_by_claimant']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73099b2a-6708-44f0-a168-d7d424d7450d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cell 6: Feature Engineering: Average per Broad Benefit and Deviation\n",
    "# Comments: Calculate the average claim amount and its deviation for each broad benefit type.\n",
    "# This helps in identifying claims that are outliers within their specific broad benefit category.\n",
    "\n",
    "df_training['average_claim_per_broad_benefit'] = df_training.groupby('broad_benefits_cleaned')['totals'].transform('mean')\n",
    "df_training['deviation_claim_per_broad_benefit'] = df_training.groupby('broad_benefits_cleaned')['totals'].transform('std').fillna(0)\n",
    "\n",
    "print(\"\\nClaim Statistics by Broad Benefit Type (re-calculated using cleaned column from Cell 4):\")\n",
    "print(df_training[['broad_benefit', 'totals', 'average_claim_per_broad_benefit', 'deviation_claim_per_broad_benefit']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfabe81-c550-4864-b19f-da20d93adbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Feature Engineering: Age and Status (Child/Spouse) Mismatch\n",
    "# Comments: Calculate age from DOB and identify potential mismatches based on 'REL' (relationship)\n",
    "# and main member's gender and age.\n",
    "\n",
    "# 'age' column (claimant's age) should already be calculated in Cell 2.\n",
    "\n",
    "# Simple check for 'CHILD' relationship: if relationship is 'CHILD' but age is > 23\n",
    "df_training['age_rel_mismatch_flag'] = ((df_training['relationship'].astype(str).str.upper() == 'CHILD') & (df_training['age'] > 25)).astype(int)\n",
    "\n",
    "# Initialize flags to 0 in case the relevant columns are missing\n",
    "df_training['spouse_gender_mismatch_flag'] = 0\n",
    "df_training['spouse_age_mismatch_flag'] = 0\n",
    "\n",
    "# --- Gender mismatch for spouses ---\n",
    "# Check if the 'main_member_gender' column exists in the DataFrame\n",
    "if 'main_member_gender' in df_training.columns:\n",
    "    # Convert claimant's gender and main member's gender to uppercase for robust comparison\n",
    "    df_training['gender(claimant)_upper'] = df_training['gender(claimant)'].astype(str).str.upper()\n",
    "    df_training['main_member_gender_upper'] = df_training['main_member_gender'].astype(str).str.upper()\n",
    "\n",
    "    # Flag if 'REL' is 'SPOUSE' AND claimant's gender is the same as the main member's gender.\n",
    "    # (Assuming a mismatch means different genders for a spouse pair)\n",
    "    df_training['spouse_gender_mismatch_flag'] = (\n",
    "        (df_training['relationship'].astype(str).str.upper() == 'SPOUSE') &\n",
    "        (df_training['gender(claimant)_upper'] == df_training['main_member_gender_upper'])\n",
    "    ).astype(int)\n",
    "\n",
    "    # Clean up temporary uppercase columns\n",
    "    df_training = df_training.drop(columns=['gender(claimant)_upper', 'main_member_gender_upper'])\n",
    "else:\n",
    "    print(\"Warning: 'main_member_gender' column not found after cleaning. Spouse gender mismatch flag will default to 0.\")\n",
    "\n",
    "# --- Age mismatch for spouses ---\n",
    "# Check if the 'age_main_member' column exists in the DataFrame\n",
    "if 'age_main_member' in df_training.columns:\n",
    "    # Convert 'age_main_member' to numeric, coercing any errors to NaN\n",
    "    df_training['age_main_member'] = pd.to_numeric(df_training['age_main_member'], errors='coerce')\n",
    "\n",
    "    # Define a reasonable age difference threshold (e.g., 15 years) for a potential mismatch\n",
    "    age_diff_threshold = 15\n",
    "\n",
    "    # Flag if 'REL' is 'SPOUSE' AND:\n",
    "    # 1. The absolute age difference between claimant and main member is greater than the threshold, OR\n",
    "    # 2. The claimant's age (representing the spouse) is suspiciously low (e.g., under 18 years old).\n",
    "    df_training['spouse_age_mismatch_flag'] = (\n",
    "        (df_training['relationship'].astype(str).str.upper() == 'SPOUSE') &\n",
    "        (\n",
    "            (np.abs(df_training['age'] - df_training['age_main_member']) > age_diff_threshold) |\n",
    "            (df_training['age'] < 18)\n",
    "        )\n",
    "    ).astype(int)\n",
    "else:\n",
    "    print(\"Warning: 'age_main_member' column not found after cleaning. Spouse age mismatch flag will default to 0.\")\n",
    "\n",
    "\n",
    "# Display results\n",
    "print(\"\\nAge and Relationship Mismatch Flags:\")\n",
    "# Dynamically build the list of columns to display to avoid errors if some new columns are not found\n",
    "display_cols = ['claimant_suddo', 'relationship', 'gender(claimant)', 'age', 'age_rel_mismatch_flag']\n",
    "if 'main_member_gender' in df_training.columns:\n",
    "    display_cols.append('main_member_gender')\n",
    "if 'spouse_gender_mismatch_flag' in df_training.columns:\n",
    "    display_cols.append('spouse_gender_mismatch_flag')\n",
    "if 'age_main_member' in df_training.columns:\n",
    "    display_cols.append('age_main_member')\n",
    "if 'spouse_age_mismatch_flag' in df_training.columns:\n",
    "    display_cols.append('spouse_age_mismatch_flag')\n",
    "\n",
    "print(df_training[display_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656115da-3b5a-415d-8f2d-c685b05709fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Feature Engineering: Mean, Deviation, and % Deviation for Service Offered and Price Charged\n",
    "# Comments: Assuming 'ailment' is the service offered and 'totals' is the price charged.\n",
    "# This helps detect if a particular service is consistently over/under charged compared to its average.\n",
    "\n",
    "df_training['service_charge_mean_by_ailment'] = df_training.groupby('ailments')['total_payable'].transform('mean')\n",
    "df_training['service_charge_dev_by_ailment'] = df_training.groupby('ailments')['total_payable'].transform('std').fillna(0)\n",
    "df_training['service_charge_pct_dev_by_ailment'] = (\n",
    "    (df_training['total_payable'] - df_training['service_charge_mean_by_ailment']) / df_training['service_charge_mean_by_ailment']\n",
    ").fillna(0)\n",
    "\n",
    "print(\"\\nService Charge Statistics by Ailment:\")\n",
    "print(df_training[['ailments', 'total_payable', 'service_charge_mean_by_ailment', 'service_charge_dev_by_ailment', 'service_charge_pct_dev_by_ailment']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bd139c-312b-49e4-8c09-b980ab3d7d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from difflib import SequenceMatcher  # Built-in fuzzy matching alternative\n",
    "\n",
    "# Define conditions with severity weights (1-5 scale, 5 = most severe mismatch)\n",
    "condition_sets = {\n",
    "    # Format: (condition_patterns, gender/age_filter, weight, is_borderline)\n",
    "    'female_conditions': (\n",
    "        ['pregnancy', 'prenatal', 'postpartum', 'gestational', 'ovarian', \n",
    "         'cervical', 'endometriosis', 'uterine fibroids', 'menopause', \n",
    "         'pcos', 'ectopic pregnancy', 'premenstrual', 'vaginitis', \n",
    "         'pelvic inflammatory', 'mammogram', 'hysterectomy', \n",
    "         'tubal ligation', 'preeclampsia', 'placenta previa', 'uterine', \n",
    "          'vaginosis', 'vaginitis', 'abortion', 'cyesis', 'a.n.c', 'vertex delivery'\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "],\n",
    "        lambda df: df['gender(claimant)'].str.upper() == 'M',\n",
    "        5,  # Very severe mismatch\n",
    "        False\n",
    "    ),\n",
    "    \n",
    "    'borderline_female_conditions': (\n",
    "        ['breast cancer', 'mastectomy', 'gynecologic'],\n",
    "        lambda df: df['gender(claimant)'].str.upper() == 'M',\n",
    "        3,  # Less severe (males can rarely have these)\n",
    "        True\n",
    "    ),\n",
    "    \n",
    "    'male_conditions': (\n",
    "        ['prostate', 'testicular', 'erectile', \n",
    "         'bph', 'vasectomy', 'peyronie', 'circumcision', 'ejaculation', 'prostatic', 'sperm' ],\n",
    "        lambda df: df['gender(claimant)'].str.upper() == 'F',\n",
    "        5,\n",
    "        False\n",
    "    ),\n",
    "    \n",
    "    'borderline_male_conditions': (\n",
    "        ['low testosterone', 'male pattern baldness'],\n",
    "        lambda df: df['gender(claimant)'].str.upper() == 'F',\n",
    "        2,  # Females can have testosterone issues too\n",
    "        True\n",
    "    ),\n",
    "    \n",
    "    'pediatric_conditions': (\n",
    "        ['pediatric', 'well-child', 'vaccination', 'dtap', 'mmr', 'croup',\n",
    "         'diaper rash', 'neonatal', 'childhood leukemia', 'adhd diagnosis',\n",
    "         'pediatric epilepsy', 'congenital heart', 'school physical'],\n",
    "        lambda df: df['age(claimant)'] >= 18,\n",
    "        4,\n",
    "        False\n",
    "    ),\n",
    "    \n",
    "    'adult_conditions_young': (\n",
    "        ['alzheimer', 'dementia', 'osteoporosis', 'colonoscopy',\n",
    "         'prostate exam', 'mammogram', 'presbyopia'],\n",
    "        lambda df: df['age(claimant)'] < 40,  # More granular age bracket\n",
    "        4,\n",
    "        False\n",
    "    ),\n",
    "    \n",
    "    'adult_conditions_elderly': (\n",
    "        ['geriatric', 'senior', 'memory care', 'assisted living'],\n",
    "        lambda df: df['age(claimant)'] < 65,\n",
    "        5,\n",
    "        False\n",
    "    ),\n",
    "    \n",
    "    'borderline_adult_conditions': (\n",
    "        ['hypertension', 'type 2 diabetes', 'cataract'],\n",
    "        lambda df: df['age(claimant)'] < 18,  # Rare but possible in children\n",
    "        2,\n",
    "        True\n",
    "    )\n",
    "}\n",
    "\n",
    "def similar(a, b, threshold=0.85):\n",
    "    \"\"\"Check if strings are similar using difflib\"\"\"\n",
    "    return SequenceMatcher(None, a, b).ratio() >= threshold\n",
    "\n",
    "def detect_mismatches(df, condition_sets):\n",
    "    \"\"\"\n",
    "    Enhanced mismatch detection without external dependencies\n",
    "    Returns DataFrame with weighted mismatch scores and flags\n",
    "    \"\"\"\n",
    "    # Initialize columns\n",
    "    df['mismatch_score'] = 0\n",
    "    df['definite_mismatch'] = 0\n",
    "    df['borderline_mismatch'] = 0\n",
    "    df['mismatch_details'] = ''\n",
    "    \n",
    "    # Convert ailments to lowercase for case-insensitive matching\n",
    "    ailments = df['ailments'].astype(str).str.lower()\n",
    "    \n",
    "    # Check diagnosis name patterns\n",
    "    for name, (patterns, filter_fn, weight, is_borderline) in condition_sets.items():\n",
    "        # Fuzzy match using difflib\n",
    "        matches = np.zeros(len(df), dtype=bool)\n",
    "        for pattern in patterns:\n",
    "            matches |= ailments.apply(lambda x: any(\n",
    "                similar(pattern, word) \n",
    "                for word in x.split()\n",
    "            ))\n",
    "        \n",
    "        mask = matches & filter_fn(df)\n",
    "        df.loc[mask, 'mismatch_score'] += weight\n",
    "        if is_borderline:\n",
    "            df.loc[mask, 'borderline_mismatch'] = 1\n",
    "            df.loc[mask, 'mismatch_details'] += f'[Borderline:{name}]'\n",
    "        else:\n",
    "            df.loc[mask, 'definite_mismatch'] = 1\n",
    "            df.loc[mask, 'mismatch_details'] += f'[Definite:{name}]'\n",
    "    \n",
    "    # Age-specific enhancements\n",
    "    df['age_bracket'] = pd.cut(\n",
    "        df['age(claimant)'],\n",
    "        bins=[0, 2, 12, 18, 40, 65, 120],\n",
    "        labels=['infant', 'child', 'teen', 'young_adult', 'adult', 'elderly']\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply to your dataframe\n",
    "df_training = detect_mismatches(df_training, condition_sets)\n",
    "\n",
    "# Create final flags based on thresholds\n",
    "df_training['high_confidence_fraud'] = (\n",
    "    (df_training['definite_mismatch'] == 1) & \n",
    "    (df_training['mismatch_score'] >= 4)\n",
    ").astype(int)\n",
    "\n",
    "df_training['needs_review'] = (\n",
    "    (df_training['borderline_mismatch'] == 1) |\n",
    "    ((df_training['mismatch_score'] >= 2) & \n",
    "     (df_training['mismatch_score'] < 4))\n",
    ").astype(int)\n",
    "\n",
    "print(\"\\nEnhanced Mismatch Detection Results:\")\n",
    "print(df_training[['gender(claimant)', 'age(claimant)', 'age_bracket', 'ailments', \n",
    "                   'mismatch_score', 'high_confidence_fraud', \n",
    "                   'needs_review', 'mismatch_details']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e4849b-e346-4dac-b258-624c8d5dfc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Feature Engineering: Average, Deviation, and % Deviation of Provider and Service\n",
    "# Comments: Calculate statistics for 'PAYEE' (provider) and 'AILMENT' (service).\n",
    "# This helps identify providers with unusually high/low charges for specific services.\n",
    "\n",
    "df_training['provider_service_mean_charge'] = df_training.groupby(['provider', 'ailments'])['total_payable'].transform('mean').fillna(0)\n",
    "df_training['provider_service_dev_charge'] = df_training.groupby(['provider', 'ailments'])['total_payable'].transform('std').fillna(0)\n",
    "df_training['provider_service_pct_dev_charge'] = (\n",
    "    (df_training['total_payable'] - df_training['provider_service_mean_charge']) / df_training['provider_service_mean_charge']\n",
    ").fillna(0)\n",
    "\n",
    "print(\"\\nProvider and Service Charge Statistics:\")\n",
    "print(df_training[['provider', 'ailments', 'total_payable', 'provider_service_mean_charge', 'provider_service_dev_charge', 'provider_service_pct_dev_charge']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2c4a51-e346-4fc6-be36-2251135a345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Feature Engineering: Number of Repeat Claimants\n",
    "df_training['repeat_claimant_count'] = df_training.groupby('claimant_suddo')['member_suddo'].transform('count')\n",
    "\n",
    "print(\"\\nRepeat Claimant Count:\")\n",
    "print(df_training[['claimant_suddo', 'repeat_claimant_count']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c0abf9-6414-45b9-ba49-6d07e2d01285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Feature Engineering: Claim Ratio and High Claim Flag\n",
    "df_training['claim_ratio'] = (df_training['total_payable'] / df_training['cover_limit']).fillna(0)\n",
    "df_training['high_claim_flag'] = (df_training['total_payable'] > (0.8 * df_training['cover_limit'])).astype(int)\n",
    "\n",
    "print(\"\\nClaim Ratio and High Claim Flag:\")\n",
    "print(df_training[['total_payable', 'cover_limit', 'claim_ratio', 'high_claim_flag']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a20c8a-e777-4282-9c32-4b59b2c21d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Feature Engineering: Average Claim per User\n",
    "df_training['average_claim_per_user'] = df_training.groupby('member_suddo')['total_payable'].transform('mean').fillna(0)\n",
    "\n",
    "print(\"\\nAverage Claim per User:\")\n",
    "print(df_training[['member_suddo', 'total_payable', 'average_claim_per_user']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a822f2-72ed-4006-ab82-b977fb39f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Feature Engineering: Claim Amount Variance (Claimant and Company)\n",
    "df_training['claim_amount_variance_claimant'] = df_training.groupby('claimant_suddo')['total_payable'].transform('var').fillna(0)\n",
    "df_training['claim_amount_variance_company'] = df_training.groupby('company')['total_payable'].transform('var').fillna(0)\n",
    "\n",
    "print(\"\\nClaim Amount Variance by Claimant and Company:\")\n",
    "print(df_training[['claimant_suddo', 'company', 'total_payable', 'claim_amount_variance_claimant', \n",
    "                   'claim_amount_variance_company']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c082772a-49f5-409d-a091-12b21a621b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Feature Engineering: Company Total Claims\n",
    "df_training['company_total_claims'] = df_training.groupby('company')['total_payable'].transform('sum').fillna(0)\n",
    "\n",
    "print(\"\\nCompany Total Claims:\")\n",
    "print(df_training[['company', 'total_payable', 'company_total_claims']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddddbd18-f326-4647-999a-45be978e4c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17: Feature Engineering: Medical & Benefit Features\n",
    "# Using the exact column names from your dataset\n",
    "\n",
    "# Label Encoding for categorical features\n",
    "le_ailment = LabelEncoder()\n",
    "df_training['ailment_type_encoded'] = le_ailment.fit_transform(df_training['ailments'].astype(str))\n",
    "\n",
    "le_benefit = LabelEncoder()\n",
    "df_training['benefit_type_encoded'] = le_benefit.fit_transform(df_training['benefit'].astype(str))\n",
    "\n",
    "le_broad_benefits = LabelEncoder()\n",
    "df_training['broad_benefits_encoded'] = le_broad_benefits.fit_transform(df_training['broad_benefit'].astype(str))\n",
    "\n",
    "# Diagnosis Group (Placeholder)\n",
    "def map_diagnosis_group(ailment):\n",
    "    if pd.isna(ailment):\n",
    "        return 'Unknown_Diagnosis'\n",
    "    ailment = str(ailment).lower()\n",
    "    if 'fever' in ailment:\n",
    "        return 'Fever_Related'\n",
    "    elif 'pain' in ailment:\n",
    "        return 'Pain_Related'\n",
    "    elif 'dental' in ailment:\n",
    "        return 'Dental_Related'\n",
    "    elif 'maternity' in ailment or 'cysis' in ailment:\n",
    "        return 'Maternity_Related'\n",
    "    else:\n",
    "        return 'Other_Diagnosis'\n",
    "\n",
    "df_training['diagnosis_group'] = df_training['ailments'].apply(map_diagnosis_group)\n",
    "le_diagnosis_group = LabelEncoder()\n",
    "df_training['diagnosis_group_encoded'] = le_diagnosis_group.fit_transform(df_training['diagnosis_group'])\n",
    "\n",
    "# Hospital Risk Score (from fraud claims mapping)\n",
    "# Using 'payee' from fraud_claims1 and 'reported_fraud_cases' from fraud_claims2\n",
    "all_fraud_hospitals_names_1 = df_fraud_claims1['payee'].dropna().astype(str).str.strip().str.lower().str.replace(' ', '_').unique()\n",
    "all_fraud_hospitals_names_2 = df_fraud_claims2['reported_fraud_cases'].dropna().astype(str).str.strip().str.lower().str.replace(' ', '_').unique()\n",
    "all_fraud_hospitals = np.unique(np.concatenate([all_fraud_hospitals_names_1, all_fraud_hospitals_names_2]))\n",
    "\n",
    "df_training['provider_cleaned'] = df_training['provider'].astype(str).str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "hospital_fraud_counts = {}\n",
    "for hospital in all_fraud_hospitals:\n",
    "    count = 0\n",
    "    count += df_fraud_claims1['payee'].astype(str).str.lower().str.replace(' ', '_').fillna('').str.contains(hospital, regex=False).sum()\n",
    "    count += df_fraud_claims2['reported_fraud_cases'].astype(str).str.lower().str.replace(' ', '_').fillna('').str.contains(hospital, regex=False).sum()\n",
    "    hospital_fraud_counts[hospital] = count\n",
    "\n",
    "df_training['hospital_risk_score'] = df_training['provider_cleaned'].map(hospital_fraud_counts).fillna(0)\n",
    "\n",
    "print(\"\\nMedical & Benefit Features:\")\n",
    "print(df_training[['ailments', 'ailment_type_encoded', 'benefit', 'benefit_type_encoded', \n",
    "                   'broad_benefits_encoded', 'diagnosis_group', 'diagnosis_group_encoded', \n",
    "                   'provider', 'hospital_risk_score']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cd778b-bbec-45a3-9d1e-9375ebe1cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's examine the exact column names in your DataFrames\n",
    "print(\"Training Dataset Columns:\")\n",
    "print(df_training.columns.tolist())\n",
    "\n",
    "print(\"\\nFraud Claims 1 Columns:\")\n",
    "print(df_fraud_claims1.columns.tolist())\n",
    "\n",
    "print(\"\\nFraud Claims 2 Columns:\")\n",
    "print(df_fraud_claims2.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb9452-f29e-4baf-8786-abc35ec66b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18: Feature Engineering: Behavioral & Derived Features\n",
    "# is_first_claim for CLAIMANT or MAIN MEMBER\n",
    "df_training['is_first_claim_claimant'] = df_training.groupby('claimant_suddo')['ailment_date'].rank(method='first') == 1\n",
    "df_training['is_first_claim_main_member'] = df_training.groupby('member_suddo')['ailment_date'].rank(method='first') == 1\n",
    "\n",
    "# claim_pattern_anomaly_score (Isolation Forest)\n",
    "numerical_features_for_if = [\n",
    "    'total_payable', 'cover_limit', 'days_since_last_visit',\n",
    "    'claim_amount_mean_by_claimant', 'claim_amount_dev_by_claimant',\n",
    "    'average_claim_per_broad_benefit', 'deviation_claim_per_broad_benefit',\n",
    "    'service_charge_mean_by_ailment', 'service_charge_dev_by_ailment',\n",
    "    'provider_service_mean_charge', 'provider_service_dev_charge',\n",
    "    'repeat_claimant_count', 'claim_ratio', 'average_claim_per_user',\n",
    "    'claim_amount_variance_claimant', 'claim_amount_variance_company',\n",
    "    'company_total_claims', 'age', 'hospital_risk_score',\n",
    "    'is_inpatient_benefit', 'is_outpatient_benefit', 'is_optical_benefit',\n",
    "    'is_dental_benefit', 'is_maternity_benefit', 'is_last_expense_benefit',\n",
    "    'age_rel_mismatch_flag', 'spouse_gender_mismatch_flag',\n",
    "    'gender_diagnosis_mismatch_flag', 'age_diagnosis_mismatch_flag'\n",
    "]\n",
    "\n",
    "for col in numerical_features_for_if:\n",
    "    if col in df_training.columns:\n",
    "        df_training[col] = df_training[col].replace([np.inf, -np.inf], np.nan)\n",
    "        df_training[col] = df_training[col].fillna(df_training[col].median())\n",
    "\n",
    "iso_forest = IsolationForest(random_state=42, contamination=0.01)\n",
    "features_for_if_present = [col for col in numerical_features_for_if if col in df_training.columns]\n",
    "df_training['claim_pattern_anomaly_score'] = iso_forest.fit_predict(df_training[features_for_if_present])\n",
    "df_training['claim_pattern_anomaly_score'] = df_training['claim_pattern_anomaly_score'].apply(lambda x: 1 if x == -1 else 0)\n",
    "\n",
    "# company_claim_trend_zscore\n",
    "df_training['provider_claim_zscore'] = df_training.groupby('provider')['total_payable'].transform(lambda x: (x - x.mean()) / x.std()).fillna(0)\n",
    "\n",
    "# rel_frequency_score\n",
    "df_training['rel_frequency_score'] = df_training.groupby('relationship')['member_suddo'].transform('count')\n",
    "\n",
    "# is_high_risk_location\n",
    "df_training['is_high_risk_location'] = df_training['provider_cleaned'].isin(all_fraud_hospitals).astype(int)\n",
    "\n",
    "# company_fraud_incident_flag\n",
    "# Using correct column names from your dataset:\n",
    "# For df_fraud_claims1: 'company' column doesn't exist, using 'payee' instead\n",
    "# For df_fraud_claims2: using 'reported_fraud_cases' instead of 'subject'\n",
    "fraudulent_entities_from_fraud1 = df_fraud_claims1['payee'].dropna().astype(str).str.lower().unique()\n",
    "fraudulent_entities_from_fraud2 = df_fraud_claims2['reported_fraud_cases'].dropna().astype(str).str.lower().unique()\n",
    "all_fraudulent_companies = np.unique(np.concatenate([fraudulent_entities_from_fraud1, fraudulent_entities_from_fraud2]))\n",
    "\n",
    "df_training['company_fraud_incident_flag'] = df_training['company'].astype(str).str.lower().isin(all_fraudulent_companies).astype(int)\n",
    "\n",
    "print(\"\\nBehavioral & Derived Features:\")\n",
    "print(df_training[[\n",
    "    'claimant_suddo', 'is_first_claim_claimant', 'member_suddo', 'is_first_claim_main_member',\n",
    "    'claim_pattern_anomaly_score', 'provider_claim_zscore', 'rel_frequency_score',\n",
    "    'is_high_risk_location', 'company_fraud_incident_flag'\n",
    "]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824ecfdf-8ccc-4e99-a6e5-eefe13f6a5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming df_training is your main DataFrame\n",
    "\n",
    "# --- New Feature 1: Time since last claim for a similar ailment ---\n",
    "# This requires sorting by claimant, ailment, and date.\n",
    "df_training = df_training.sort_values(by=['claimant_suddo', 'ailments', 'ailment_date'])\n",
    "df_training['days_since_last_ailment'] = df_training.groupby(['claimant_suddo', 'ailments'])['ailment_date'].diff().dt.days.fillna(0)\n",
    "\n",
    "# --- New Feature 2: Time since last claim at the same provider ---\n",
    "# This requires sorting by claimant, provider, and date.\n",
    "df_training = df_training.sort_values(by=['claimant_suddo', 'provider', 'ailment_date'])\n",
    "df_training['days_since_last_provider_visit'] = df_training.groupby(['claimant_suddo', 'provider'])['ailment_date'].diff().dt.days.fillna(0)\n",
    "\n",
    "# --- New Feature 3: Day of the week and month ---\n",
    "# These are simple extractions from the ailment date.\n",
    "df_training['day_of_week'] = df_training['ailment_date'].dt.dayofweek\n",
    "df_training['month_of_year'] = df_training['ailment_date'].dt.month\n",
    "\n",
    "# --- New Feature 4: Provider Behavior Statistics ---\n",
    "# Group by provider to calculate their average claim amount and claim count\n",
    "provider_stats = df_training.groupby('provider')['total_payable'].agg(['mean', 'count']).reset_index()\n",
    "provider_stats.rename(columns={'mean': 'provider_avg_claim', 'count': 'provider_claim_count'}, inplace=True)\n",
    "\n",
    "# Merge these new features back into the main DataFrame\n",
    "df_training = df_training.merge(provider_stats, on='provider', how='left')\n",
    "\n",
    "print(\"New Features Added:\")\n",
    "print(df_training[['days_since_last_ailment', 'days_since_last_provider_visit', \n",
    "                   'day_of_week', 'month_of_year', 'provider_avg_claim', 'provider_claim_count']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bc1684-7e30-4857-8044-d87b15e8f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 19: Final Feature Selection for Model Building\n",
    "numerical_features = [\n",
    "    'days_since_last_visit',\n",
    "    'claim_amount_mean_by_claimant', 'claim_amount_dev_by_claimant', 'claim_amount_var_by_claimant',\n",
    "    'average_claim_per_broad_benefit', 'deviation_claim_per_broad_benefit',\n",
    "    'age', 'age_rel_mismatch_flag', 'spouse_gender_mismatch_flag',\n",
    "    'service_charge_mean_by_ailment', 'service_charge_dev_by_ailment', 'service_charge_pct_dev_by_ailment',\n",
    "    'gender_diagnosis_mismatch_flag', 'age_diagnosis_mismatch_flag',\n",
    "    'provider_service_mean_charge', 'provider_service_dev_charge', 'provider_service_pct_dev_charge',\n",
    "    'repeat_claimant_count', 'claim_ratio', 'high_claim_flag',\n",
    "    'average_claim_per_user', 'claim_amount_variance_claimant', 'claim_amount_variance_company',\n",
    "    'company_total_claims',\n",
    "    'ailment_type_encoded', 'benefit_type_encoded', 'broad_benefits_encoded', 'diagnosis_group_encoded',\n",
    "    'hospital_risk_score',\n",
    "    'is_first_claim_claimant', 'is_first_claim_main_member', 'claim_pattern_anomaly_score',\n",
    "    'provider_claim_zscore', 'rel_frequency_score', 'is_high_risk_location', 'company_fraud_incident_flag',\n",
    "    'is_inpatient_benefit', 'is_outpatient_benefit', 'is_optical_benefit',\n",
    "    'is_dental_benefit', 'is_maternity_benefit', 'is_last_expense_benefit'\n",
    "]\n",
    "\n",
    "categorical_columns_to_keep_original = [\n",
    "    'gender(claimant)', 'relationship', 'company', 'broad_benefit', \n",
    "    'ailments', 'benefit', 'provider', 'diagnosis_group'\n",
    "]\n",
    "\n",
    "# Add main_member_gender if it exists (from your columns list it's 'main_member_gender')\n",
    "if 'main_member_gender' in df_training.columns and df_training['main_member_gender'].dtype == 'object':\n",
    "    categorical_columns_to_keep_original.append('main_member_gender')\n",
    "\n",
    "# Filter to only include columns that exist in the dataframe\n",
    "final_numerical_features = [col for col in numerical_features if col in df_training.columns]\n",
    "final_features_for_model = list(set(final_numerical_features + categorical_columns_to_keep_original))\n",
    "\n",
    "print(\"\\nNumber of final features:\", len(final_features_for_model))\n",
    "print(\"\\nSample of Final Features for Model:\")\n",
    "print(df_training[final_features_for_model].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4c53d1-a7dc-484e-a1ca-74697b4760eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's add all required imports at the top\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, classification_report, \n",
    "                           roc_auc_score, confusion_matrix)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cell 20: Model Building - Complete Version\n",
    "try:\n",
    "    # Prepare the feature matrix X with one-hot encoding\n",
    "    current_categorical_cols = [col for col in categorical_columns_to_keep_original if col in df_training.columns]\n",
    "    X = pd.get_dummies(df_training[final_features_for_model], \n",
    "                      columns=current_categorical_cols, \n",
    "                      dummy_na=False,\n",
    "                      drop_first=True)\n",
    "\n",
    "    # Define the target variable (using the anomaly score we created)\n",
    "    y = df_training['claim_pattern_anomaly_score']\n",
    "\n",
    "    # Ensure target variable isn't in features\n",
    "    if 'claim_pattern_anomaly_score' in X.columns:\n",
    "        X = X.drop('claim_pattern_anomaly_score', axis=1)\n",
    "\n",
    "    # Split data into training and testing sets (70% train, 30% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.3, \n",
    "        random_state=42, \n",
    "        stratify=y  # Maintain class balance\n",
    "    )\n",
    "\n",
    "    # Initialize and train a RandomForestClassifier with balanced class weights\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        random_state=42, \n",
    "        class_weight='balanced',\n",
    "        max_depth=10,\n",
    "        min_samples_split=10\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]  # Probability estimates\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(\"\\n--- Model Evaluation ---\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    # Display feature importances\n",
    "    feature_importances = pd.Series(\n",
    "        model.feature_importances_, \n",
    "        index=X.columns\n",
    "    ).sort_values(ascending=False)\n",
    "\n",
    "    print(\"\\nFeature Importances (Top 20):\")\n",
    "    print(feature_importances.head(20))\n",
    "\n",
    "    # Additional evaluation metrics\n",
    "    print(\"\\nAdditional Metrics:\")\n",
    "    print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred_proba))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # Plot feature importances\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    feature_importances.head(20).plot(kind='barh')\n",
    "    plt.title('Top 20 Important Features')\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.ylabel('Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"Make sure all required columns exist in df_training\")\n",
    "    print(\"Current columns in df_training:\", df_training.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971f2ebd-da7e-4219-b89a-edc49d43d07b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Display the first few rows of your dataset\n",
    "df_training.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2834636-6868-40e1-b3a7-cabe3a7d92ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "print(platform.python_version())\n",
    "print(platform.architecture())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ccfb72-8c44-4caf-b76c-68a923cb6285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# PyTorch for Autoencoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Load your data\n",
    "df = df_training.copy()\n",
    "\n",
    "# Define features to use\n",
    "features = [\n",
    "    'age(claimant)', 'days_since_last_visit', 'day_of_month_visited',\n",
    "    'month_visited', 'hospital_risk_score', 'claim_pattern_anomaly_score',\n",
    "    'provider_claim_zscore', 'rel_frequency_score'\n",
    "]\n",
    "\n",
    "X = df[features].copy().fillna(0)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e324207-16df-4ba1-ae80-8d5a810ff027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# === Step 1: Scale features with RobustScaler ===\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)  # X is your original feature matrix\n",
    "\n",
    "# === Step 2: Train KMeans model ===\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "kmeans_cluster = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# === Step 3: Store cluster labels in DataFrame ===\n",
    "df['kmeans_cluster'] = kmeans_cluster\n",
    "\n",
    "# === Step 4: Calculate silhouette score ===\n",
    "score = silhouette_score(X_scaled, kmeans_cluster)\n",
    "print(f\"Silhouette Score: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40826c4a-c13f-4d32-98bc-4bfd42936ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "\n",
    "iso = IsolationForest(\n",
    "    n_estimators=300,         # a bit more trees for stability\n",
    "    contamination=0.05,       # target anomaly proportion (used for IF’s internal threshold)\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ").fit(X_scaled)\n",
    "\n",
    "# Two scoring APIs:\n",
    "# - decision_function: higher = more normal (less anomalous)\n",
    "# - score_samples:     higher = more normal (less anomalous) but on a different scale\n",
    "# We invert ONE of them so that higher = riskier\n",
    "if_decision = iso.decision_function(X_scaled)         # higher = safer\n",
    "if_component = -if_decision                           # invert -> higher = riskier (✅)\n",
    "\n",
    "# Alternatively:\n",
    "# if_component = -iso.score_samples(X_scaled)         # also higher = riskier (✅)\n",
    "\n",
    "df['if_component'] = if_component.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52210f67-0029-433b-8b5f-bbf6457807e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def rank01(a):\n",
    "    a = np.asarray(a, dtype=float)\n",
    "    a[np.isnan(a)] = np.nanmedian(a)\n",
    "    r = a.argsort().argsort().astype(float)\n",
    "    return r / max(len(a) - 1, 1)\n",
    "\n",
    "parts = [\n",
    "    rank01(df[\"if_component\"].values),             # IF (inverted) -> higher = riskier\n",
    "    rank01(df[\"autoencoder_anomaly_score\"].values),# AE error      -> higher = riskier\n",
    "    rank01(df[\"kmeans_min_distance\"].values)       # KMeans dist   -> higher = riskier\n",
    "]\n",
    "\n",
    "df[\"combined_anomaly_score\"] = np.mean(parts, axis=0)  # 0..1, higher = riskier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df618da-9ec8-4844-a4e4-7832ffdec6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance to the closest cluster center (higher = farther = riskier)\n",
    "kmeans_min_dist = kmeans.transform(X_scaled).min(axis=1)\n",
    "df['kmeans_min_distance'] = kmeans_min_dist.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8df225-b83c-4e47-b198-a75907090456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to torch tensors\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "dataset = TensorDataset(X_tensor)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, input_dim),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "model = Autoencoder(input_dim=X_tensor.shape[1])\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(20):\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        data = batch[0]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/20, Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f029fe-815a-4e35-a3ea-e95c86c14167",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    recon = model(X_tensor)  # shape: [n_samples, n_features]\n",
    "    # MSE per row (you can also try MAE which is more robust to outliers)\n",
    "   mae = torch.mean(torch.abs(recon - X_tensor), dim=1).cpu().numpy()\n",
    "df[\"autoencoder_anomaly_score\"] = mae  # higher = more anomalous ✅\n",
    "print(df[\"autoencoder_anomaly_score\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6129955f-fc8c-49f3-ad34-84fed94b8238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def rank01(a: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Ranks to [0,1]; robust to scale/outliers/NaNs.\"\"\"\n",
    "    a = np.asarray(a, dtype=float)\n",
    "    if np.isnan(a).any():\n",
    "        a[np.isnan(a)] = np.nanmedian(a)\n",
    "    r = a.argsort().argsort().astype(float)\n",
    "    return r / max(len(a) - 1, 1)\n",
    "\n",
    "parts = []\n",
    "\n",
    "# --- Isolation Forest component ---\n",
    "# Expect a CONTINUOUS score with higher = riskier.\n",
    "# If you previously used fit_predict (±1 labels), this will catch it.\n",
    "if 'if_component' in df.columns:\n",
    "    if_vec = df['if_component'].astype(float).values\n",
    "else:\n",
    "    # fall back to your existing column name\n",
    "    if 'iso_anomaly_score' not in df.columns:\n",
    "        raise ValueError(\"Need either df['if_component'] (preferred) or df['iso_anomaly_score'].\")\n",
    "    raw = df['iso_anomaly_score'].astype(float).values\n",
    "\n",
    "    # guard: if it's just labels (-1/+1), stop and fix upstream\n",
    "    uniq = pd.Series(np.unique(raw)).sort_values().tolist()\n",
    "    if set(uniq).issubset({-1.0, 1.0}):\n",
    "        raise ValueError(\n",
    "            \"iso_anomaly_score looks like labels (-1/+1). \"\n",
    "            \"Compute a continuous score instead, e.g.: \"\n",
    "            \"df['if_component'] = -iso.decision_function(X_scaled)\"\n",
    "        )\n",
    "    # If raw is already oriented as higher=riskier, keep it.\n",
    "    # If it's the decision_function (higher=safer), invert it upstream instead of guessing here.\n",
    "    if_vec = raw\n",
    "\n",
    "parts.append(rank01(if_vec))\n",
    "\n",
    "# --- Autoencoder reconstruction error (higher = riskier) ---\n",
    "if 'autoencoder_anomaly_score' in df.columns:\n",
    "    parts.append(rank01(df['autoencoder_anomaly_score'].astype(float).values))\n",
    "else:\n",
    "    print(\"[WARN] 'autoencoder_anomaly_score' not found; combining without AE.\")\n",
    "\n",
    "# --- Optional: KMeans distance to nearest centroid (higher = farther = riskier) ---\n",
    "if 'kmeans_min_distance' in df.columns:\n",
    "    parts.append(rank01(df['kmeans_min_distance'].astype(float).values))\n",
    "\n",
    "# --- Combine (simple average of ranks) ---\n",
    "df['combined_anomaly_score'] = np.mean(parts, axis=0)  # 0..1, higher = riskier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb22952-2720-471b-88a4-150097fac44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Time-aware validation slice + frozen threshold =====\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, json\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# --- Config ---\n",
    "DATE_COL    = \"ailment_date\"   # your dataset has this column\n",
    "REVIEW_RATE = 0.10             # e.g., target 10% review capacity\n",
    "VERSION     = \"v1\"             # bump when you recalibrate\n",
    "\n",
    "# --- Parse dates robustly (Kenya-style dd/mm/yyyy and also '2/6/2024') ---\n",
    "df = df.copy()\n",
    "# If column is numeric Excel serials, handle that; else assume strings with day-first\n",
    "if np.issubdtype(df[DATE_COL].dtype, np.number):\n",
    "    parsed = pd.to_datetime(df[DATE_COL], errors=\"coerce\", origin=\"1899-12-30\", unit=\"D\")\n",
    "else:\n",
    "    parsed = pd.to_datetime(df[DATE_COL], errors=\"coerce\", dayfirst=True)\n",
    "\n",
    "df[\"_dt\"] = parsed\n",
    "df = df.dropna(subset=[\"_dt\"]).sort_values(\"_dt\")\n",
    "\n",
    "# --- Use most recent ~20% as validation (you can also set a calendar cutoff if preferred) ---\n",
    "cutoff = df[\"_dt\"].quantile(0.80)   # first 80% \"train-ish\", last 20% \"validation-ish\"\n",
    "df_valid = df[df[\"_dt\"] >= cutoff].copy()\n",
    "print(f\"Validation window: {df_valid['_dt'].min().date()} → {df_valid['_dt'].max().date()} | n={len(df_valid):,}\")\n",
    "\n",
    "# --- Combine components via rank-averaging (robust, scale-free) ---\n",
    "def rank01(a):\n",
    "    a = np.asarray(a, dtype=float)\n",
    "    a[np.isnan(a)] = np.nanmedian(a)\n",
    "    r = a.argsort().argsort().astype(float)\n",
    "    return r / max(len(a) - 1, 1)\n",
    "\n",
    "parts = []\n",
    "need_cols = []\n",
    "\n",
    "if 'if_component' in df_valid.columns:\n",
    "    parts.append(rank01(df_valid['if_component'].values))\n",
    "else:\n",
    "    need_cols.append('if_component')\n",
    "\n",
    "if 'autoencoder_anomaly_score' in df_valid.columns:\n",
    "    parts.append(rank01(df_valid['autoencoder_anomaly_score'].values))\n",
    "\n",
    "if 'kmeans_min_distance' in df_valid.columns:\n",
    "    parts.append(rank01(df_valid['kmeans_min_distance'].values))\n",
    "\n",
    "if not parts:\n",
    "    raise ValueError(f\"No anomaly components found on df_valid. Missing: {need_cols}\")\n",
    "\n",
    "df_valid['combined_anomaly_score'] = np.mean(parts, axis=0)  # 0..1, higher = riskier\n",
    "print(df_valid['combined_anomaly_score'].describe(percentiles=[.5, .9, .95, .98]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5474c-2bcd-4702-b4dd-ee9bf9319f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Freeze threshold at capacity target ---\n",
    "thr = float(np.quantile(df_valid['combined_anomaly_score'], 1 - REVIEW_RATE))\n",
    "\n",
    "tuning = {\n",
    "    \"version\": VERSION,\n",
    "    \"created_at\": datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "    \"review_rate_target\": float(REVIEW_RATE),\n",
    "    \"threshold_combo_rank\": thr,\n",
    "    \"validation_window\": {\n",
    "        \"start\": df_valid[\"_dt\"].min().strftime(\"%Y-%m-%d\"),\n",
    "        \"end\":   df_valid[\"_dt\"].max().strftime(\"%Y-%m-%d\"),\n",
    "        \"n\": int(len(df_valid))\n",
    "    },\n",
    "    # Optional: precompute a \"High\" band (top 2%) if you want a 3-band UI\n",
    "    \"band_high_cut\": float(np.quantile(df_valid['combined_anomaly_score'], 0.98))\n",
    "}\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "with open(f\"models/tuning_{VERSION}.json\", \"w\") as f:\n",
    "    json.dump(tuning, f, indent=2)\n",
    "\n",
    "print(f\"[OK] Saved frozen threshold to models/tuning_{VERSION}.json\")\n",
    "print(f\"[INFO] Threshold @ {int(REVIEW_RATE*100)}% review = {thr:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35cc220-fa19-404f-8440-903be12d2282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 3) Freeze the threshold at your capacity target and save to JSON =====\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "thr = float(np.quantile(df_valid['combined_anomaly_score'], 1 - REVIEW_RATE))\n",
    "\n",
    "tuning = {\n",
    "    \"version\": VERSION,\n",
    "    \"created_at\": datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "    \"review_rate_target\": float(REVIEW_RATE),\n",
    "    \"threshold_combo_rank\": thr,\n",
    "    \"validation_window\": {\n",
    "        \"start\": df_valid[DATE_COL].min().strftime(\"%Y-%m-%d\"),\n",
    "        \"end\":   df_valid[DATE_COL].max().strftime(\"%Y-%m-%d\"),\n",
    "        \"n\": int(len(df_valid))\n",
    "    },\n",
    "    # Optional: precompute band cuts for the UI (e.g., top 2% = High)\n",
    "    \"band_high_cut\": float(np.quantile(df_valid['combined_anomaly_score'], 0.98))\n",
    "}\n",
    "\n",
    "with open(f\"models/tuning_{VERSION}.json\", \"w\") as f:\n",
    "    json.dump(tuning, f, indent=2)\n",
    "\n",
    "print(f\"[OK] Saved frozen threshold to models/tuning_{VERSION}.json\")\n",
    "print(f\"[INFO] Threshold @ {int(REVIEW_RATE*100)}% review = {thr:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5544b5a4-5801-4622-b025-2cbf446c2db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = clf.feature_importances_\n",
    "sns.barplot(x=importances, y=X_full.columns)\n",
    "plt.title(\"Top Feature Importances\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee9e110-8708-470b-8f10-38f0257f56d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['combined_anomaly_score', 'fraud_label']].to_csv(\"anomaly_detection_report.csv\", index=False)\n",
    "print(\"✅ Report saved as 'anomaly_detection_report.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415799a3-5902-46bc-84f8-6be93395077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold to define fraud: top 3% of most anomalous\n",
    "threshold = df['combined_anomaly_score'].quantile(0.97)\n",
    "df['fraud_label'] = (df['combined_anomaly_score'] > threshold).astype(int)\n",
    "\n",
    "# Optional: View distribution\n",
    "print(\"Fraud label distribution:\")\n",
    "print(df['fraud_label'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7978cba6-7f9c-4e99-8e8a-30357dce91ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter fraud-labeled claims (where fraud_label == 1)\n",
    "fraud_claims = df[df['fraud_label'] == 1]\n",
    "\n",
    "# Save to CSV\n",
    "fraud_claims.to_csv(\"suspic_claims2.csv\", index=False)\n",
    "print(\"✅ Saved flagged fraud claims to 'suspic_claims2.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d376e733-6d4e-468f-893f-3fadc2697e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the full dataset (or remaining dataset)\n",
    "y_full_pred = clf.predict(X_full)\n",
    "\n",
    "# Count the number of predicted fraudulent claims\n",
    "total_predicted_fraud = sum(y_full_pred)\n",
    "print(f\"Total predicted suspicious fraudulent claims: {total_predicted_fraud}\")\n",
    "\n",
    "# If you want to see the distribution\n",
    "print(\"\\nPredicted fraud label distribution:\")\n",
    "print(pd.Series(y_full_pred).value_counts())\n",
    "\n",
    "# Optional: Save the predictions back to the dataframe\n",
    "df['predicted_fraud_label'] = y_full_pred\n",
    "\n",
    "# If you want to save the predicted fraudulent claims to a new file\n",
    "predicted_fraud_claims = df[df['predicted_fraud_label'] == 1]\n",
    "predicted_fraud_claims.to_csv(\"predicted_sus_claims.csv\", index=False)\n",
    "print(\"✅ Saved predicted fraudulent claims to 'predicted_sus_claims.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a19a332-86cd-4e53-82ed-6a71bb95e8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EXPORT FITTED OBJECTS (tailored to your notebook) ===\n",
    "# Prereqs in your notebook:\n",
    "# - scaler: RobustScaler fitted on X\n",
    "# - kmeans: KMeans fitted on X_scaled\n",
    "# - iso: IsolationForest fitted on X_scaled\n",
    "# - features: list of feature names used to build X in the SAME ORDER\n",
    "# - df: DataFrame where df['combined_anomaly_score'] exists (from iso + autoencoder)\n",
    "# - model: trained PyTorch autoencoder (optional export below)\n",
    "\n",
    "import os, json, joblib, numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# 1) Create models/ folder\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# 2) Persist core sklearn artifacts and metadata\n",
    "artifacts = {\n",
    "    \"scaler\": scaler,                 # RobustScaler you fitted\n",
    "    \"kmeans\": kmeans,                 # KMeans you fitted\n",
    "    \"iforest\": iso,                   # IsolationForest you fitted\n",
    "    \"feature_names\": list(features),  # EXACT order used during training\n",
    "    \"feature_version\": \"f1.0\",\n",
    "    \"feature_medians\": feature_medians,\n",
    "}\n",
    "\n",
    "joblib.dump(artifacts, \"models/anomaly_v1.joblib\")\n",
    "\n",
    "# 3) (Optional) Persist the autoencoder for future use\n",
    "#    We save two things:\n",
    "#    - the model weights (state_dict)\n",
    "#    - lightweight metadata to help reconstruct the AE at inference\n",
    "#    If you don't plan to use AE at runtime yet, you can skip this block safely.\n",
    "try:\n",
    "    import torch\n",
    "    ae_meta = {\n",
    "        \"input_dim\": int(X_scaled.shape[1]),\n",
    "        \"arch\": \"fc-32-16-encoder\",   # free-text note: adjust if you change architecture\n",
    "    }\n",
    "    torch.save({\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"meta\": ae_meta\n",
    "    }, \"models/autoencoder_v1.pt\")\n",
    "    print(\"[INFO] Saved models/autoencoder_v1.pt (PyTorch).\")\n",
    "except Exception as _e:\n",
    "    print(\"[WARN] Autoencoder export skipped (no torch/model?) ->\", _e)\n",
    "\n",
    "# 4) Freeze a GLOBAL threshold from your combined score (capacity-driven)\n",
    "#    Your combined score is already in df['combined_anomaly_score'].\n",
    "#    Pick a review capacity target (e.g., top 10% flagged).\n",
    "import numpy as np\n",
    "\n",
    "review_rate = 0.10   # <<< change this to match ops capacity (e.g., 0.08 .. 0.12)\n",
    "if \"combined_anomaly_score\" not in df.columns:\n",
    "    raise ValueError(\"df['combined_anomaly_score'] not found. Make sure you computed it earlier.\")\n",
    "\n",
    "combo_valid = df[\"combined_anomaly_score\"].astype(float).to_numpy()\n",
    "thr = float(np.quantile(combo_valid, 1 - review_rate))\n",
    "\n",
    "tuning = {\n",
    "    \"version\": \"v1\",\n",
    "    \"created_at\": datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "    \"review_rate_target\": float(review_rate),\n",
    "    \"threshold_combo_rank\": thr,\n",
    "    \"notes\": \"Threshold frozen from current combined_anomaly_score distribution.\",\n",
    "    # (Optional) keep handy extra cuts for bands if you want in the UI:\n",
    "    \"band_high_cut\": float(np.quantile(combo_valid, 0.98)),\n",
    "}\n",
    "\n",
    "with open(\"models/tuning_v1.json\", \"w\") as f:\n",
    "    json.dump(tuning, f, indent=2)\n",
    "\n",
    "print(\"Saved: models/anomaly_v1.joblib and models/tuning_v1.json\")\n",
    "print(f\"[INFO] Frozen threshold @ target {review_rate:.0%} -> {thr:.6f}\")\n",
    "\n",
    "# ... your existing export code above ...\n",
    "\n",
    "print(\"Saved: models/anomaly_v1.joblib and models/tuning_v1.json\")\n",
    "print(f\"[INFO] Frozen threshold @ target {review_rate:.0%} -> {thr:.6f}\")\n",
    "\n",
    "# === OPTIONAL: copy artifacts to your Streamlit app's models/ folder ===\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# where the notebook wrote them (current notebook working dir)\n",
    "src_dir = Path.cwd() / \"models\"\n",
    "\n",
    "# where your Streamlit app expects them (adjust to your real app path)\n",
    "dst_dir = Path(\"project/models\")  # e.g., repo_root/project/models\n",
    "dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for name in [\"anomaly_v1.joblib\", \"tuning_v1.json\", \"autoencoder_v1.pt\"]:\n",
    "    src = src_dir / name\n",
    "    if src.exists():\n",
    "        shutil.copy2(src, dst_dir / name)\n",
    "        print(f\"Copied {src} -> {dst_dir/name}\")\n",
    "    else:\n",
    "        print(f\"[WARN] Not found: {src} (skipped)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721f09a7-b154-4d26-8f05-5bf422e34b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib, json\n",
    "art = joblib.load(\"models/anomaly_v1.joblib\")\n",
    "print(art.keys())        # expect: scaler, kmeans, iforest, feature_names, ...\n",
    "print(len(art[\"feature_names\"]))\n",
    "with open(\"models/tuning_v1.json\") as f:\n",
    "    print(json.load(f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe53abc2-30ed-41ba-a6ef-2155a68445cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d71d642-58ce-4e49-bd47-7b7b4effcb11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df059766-3f9c-4685-90a0-ef0180413a67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bedc095-bf40-4806-9111-ad4c7817c062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d76a8fb-98d8-4080-9054-702701eaef23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bdbae6-bd69-400a-89f1-4f12f99e8edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e205a09-0b7e-46df-9dd3-07d9e19229dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43635e4c-613e-4e8a-b453-19184f7175ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462605a5-343c-4bce-8faa-d54eac3ea2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3259bf1-63bf-46ea-951d-a844d5d5a127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8c0b3b-d378-402b-805b-e1e5e10d8f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bd8776-6fe1-4aab-8451-b7e50ee0e58b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4552f282-079c-471a-888f-fcdc78751491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2492f4-cd53-4186-9c16-c346e7a7891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_training.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e79490-64db-4b2d-a24c-37883071f765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7223d1-647b-46da-af78-020c057f0821",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
